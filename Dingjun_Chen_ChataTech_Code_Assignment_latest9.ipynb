{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zOWAugf_Vq-f",
    "outputId": "9e16af56-bd9d-4f80-828b-2e23d5f84f4b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting evaluate\n",
      "  Downloading evaluate-0.4.5-py3-none-any.whl.metadata (9.5 kB)\n",
      "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (4.0.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.0.2)\n",
      "Requirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from evaluate) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.70.16)\n",
      "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.3.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.34.1)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from evaluate) (25.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.18.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (18.1.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (3.12.14)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.14.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (1.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2025.7.14)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (6.6.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.20.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n",
      "Downloading evaluate-0.4.5-py3-none-any.whl (84 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: evaluate\n",
      "Successfully installed evaluate-0.4.5\n"
     ]
    }
   ],
   "source": [
    "!pip install evaluate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E6xbfbleQI6f",
    "outputId": "875e34d7-7beb-4a89-b7c9-1a032e82c13f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rouge_score\n",
      "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from rouge_score) (1.4.0)\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (from rouge_score) (3.9.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from rouge_score) (2.0.2)\n",
      "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from rouge_score) (1.17.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (8.2.1)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (1.5.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (4.67.1)\n",
      "Building wheels for collected packages: rouge_score\n",
      "  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24934 sha256=aaaf2b62732882403733e518919a0efd1e2ec6fd711df5624ae7310d23b1122f\n",
      "  Stored in directory: /root/.cache/pip/wheels/1e/19/43/8a442dc83660ca25e163e1bd1f89919284ab0d0c1475475148\n",
      "Successfully built rouge_score\n",
      "Installing collected packages: rouge_score\n",
      "Successfully installed rouge_score-0.1.2\n"
     ]
    }
   ],
   "source": [
    "!pip install rouge_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x1OWSjW7nDnz"
   },
   "source": [
    "When CUDAOutofMemoery errors occurred, running the following codes can eliminate some CUDAOutofMemory errors.\n",
    "But some of them still cannot be fixed. Maybe a GPU computing platform with bigger memory is really needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RLM16x_moreN",
    "outputId": "a7cca70e-aa0c-44ef-8744-7ff5e32f2338"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "import gc\n",
    "gc.collect()   ## garbage collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q93KCTIJnT3J"
   },
   "source": [
    " Code Assignment: ***Develop a question rephrasing model for the Disfl QA benchmark dataset***\n",
    "\n",
    " Code Author: **Dingjun Chen**\n",
    "\n",
    " Code Date: **From July 25 to July 30, 2025**\n",
    "\n",
    " Code Test Platform: ***Google Colab with its GPUs***\n",
    "\n",
    " **Introduction:** The following codes are using the pre-trained BART (Bidrecitional & AutoRegressive Transformer) to implement a question rephrasing model specifically tailored for the Disfl QA benchmark dataset. BART is designed to combine the strengths of BERT’s bidirectional encoding and GPT’s autoregressive generation. Thus, a fine-tuned BART variant is adept at tasks like summarization, translation, Question-Answering(QA) and sentiment analysis, etc. I am here to **use the fine-tuned BART model to extract the fluent questions from the disfluent questions, especially from those word-permutated disfluent questions**. In particular, I am using Hugging Face Transformers Library becaue it provides a high-level API for using pre-trained models, fine-tuning them on custom datasets, and deploying them in production environments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "myG518qunwhN"
   },
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "from transformers import BartTokenizer, BartForConditionalGeneration, TrainingArguments\n",
    "from transformers import EvalPrediction, Trainer, TrainerCallback\n",
    "import random, json, shutil,torch, os, evaluate\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ogycBeqYn405"
   },
   "source": [
    "Data augmentation is an optional technology to avoid overfitting in machine learning and it is the process of creating new samples by applying random transformations to the dataset.The following function is used to augment and **double training/validation datasets via the word permutation (shuffling words within a sentence)**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zDHtfFpjoC9s"
   },
   "outputs": [],
   "source": [
    "def DataAugmentation(src, label):\n",
    "  size = len(src)\n",
    "  for i in range(size):\n",
    "    listword = src[i].split()\n",
    "    random.shuffle(listword)\n",
    "    sentence_new = ' '.join(listword)\n",
    "    src.append(sentence_new)\n",
    "    label.append(label[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XTzRmI5koFz9"
   },
   "source": [
    "Tokenization is the process of converting a sequence of text into tokens. The following  definitions of the class and function  are used to tokenize data. To create a PyTorch dataset, I define a class that inherits from the torch.utils.data.Dataset class. Both __getitem__ and __len__ methods are required to be implemented for creating custom datasets becasue the PyTorch Dataset class is a Python abstract base class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fEOD4sLxogrd"
   },
   "outputs": [],
   "source": [
    "class BARTdataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        # super().__init__()\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "    ## To retrieve a specific sample and its corresponding label\n",
    "    def __getitem__(self, index):\n",
    "        # pass\n",
    "        item = {key: torch.tensor(val[index]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels['input_ids'][index])\n",
    "        return item\n",
    "    ## To return the size of the dataset, meaning the total number of samples\n",
    "    def __len__(self):\n",
    "        # pass\n",
    "        return len(self.labels['input_ids'])\n",
    "\n",
    "def tokenize_dataset(texts, labels):\n",
    "    tokenizer = BartTokenizer.from_pretrained('facebook/bart-large')\n",
    "    encodings = tokenizer(texts,  padding=True)\n",
    "    decodings = tokenizer(labels, padding=True)\n",
    "    tokenized_dataset = BARTdataset(encodings, decodings)\n",
    "    return tokenized_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xmYVS1l1on00"
   },
   "source": [
    "The following codes are used to customize the evaluation metrics and try some evaluation methods: accuracy, bleu or rouge, etc.,  otherwise the default evaluation would just have printed the loss.\n",
    "\n",
    "***Note:***\n",
    "The following code used for custom evaluation metrics are not successfully tested on Google Colab because OutOfMemoryError: \"CUDA out of memory\" occurred. These codes are developed based on my knowledge and understanding on custom evalation metrics. Once I have an opportunity to successfully test them on a GPU computing platform with bigger memory, I will update this repository in the future. All test results submitted for code assignment were generated in case of the default evaluation metric: LOSS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9s0zGOH1o_lR"
   },
   "outputs": [],
   "source": [
    "## Evaluation metrics with accuracy\n",
    "def accuracy_score(eval_pred: EvalPrediction):\n",
    "    metric = evaluate.load('accuracy')\n",
    "    predictions, labels = eval_pred.predictions.argmax(axis=1), eval_pred.label_ids\n",
    "    #logits, labels = eval_pred\n",
    "    #predictions = np.argmax(logits, axis=1) ## Find indices of max values along rows (column-wise)\n",
    "    return metric.compute(predictions=predictions, references=labels)\n",
    "\n",
    "## Evaluation metrics with bleu\n",
    "def bleu_score(eval_pred: EvalPrediction):\n",
    "    metric = evaluate.load('bleu')\n",
    "    predictions, labels = eval_pred.predictions.argmax(axis=1), eval_pred.label_ids\n",
    "    #logits, labels = eval_pred\n",
    "    #predictions = np.argmax(logits, axis=1) ## Find indices of max values along rows (column-wise)\n",
    "    return metric.compute(predictions=predictions, references=labels)\n",
    "\n",
    "## Evaluation metrics with rouge\n",
    "def rouge_score(eval_pred: EvalPrediction):\n",
    "    metric = evaluate.load('rouge')\n",
    "    predictions, labels = eval_pred.predictions.argmax(axis=1), eval_pred.label_ids\n",
    "    #logits, labels = eval_pred\n",
    "    #predictions = np.argmax(logits, axis=1) ## Find indices of max values along rows (column-wise)\n",
    "    return metric.compute(predictions=predictions, references=labels, use_aggregator=True)\n",
    "\n",
    "## Combination of multiple evaluation metrics\n",
    "def combination_compute_metrics1(eval_pred: EvalPrediction):\n",
    "    ## Create dictionary to store Accuracy, Bleu and Rouge metrics\n",
    "    metrics = {}  ## dictionary\n",
    "    ## Compute Accuracy score\n",
    "    metrics['Accuracy'] = accuracy_score(eval_pred)\n",
    "    ## Compute Rouge score\n",
    "    metrics['rouge1'], metrics['rougeL'] = rouge_score(eval_pred)\n",
    "    ## Compute Bleu score\n",
    "    metrics['bleu'] = bleu_score(eval_pred)\n",
    "    return metrics\n",
    "\n",
    "## Using a callback to trainer because Huggingface does not explicitly log the train accuracy\n",
    "## Adding a custom callback which calls the evaluate() method with train_dataset at the end of every callback.\n",
    "class CustomCallback(TrainerCallback):\n",
    "\n",
    "    def __init__(self, trainer) -> None:\n",
    "        super().__init__()\n",
    "        self._trainer = trainer\n",
    "\n",
    "    def on_epoch_end(self, args, state, control, **kwargs):\n",
    "        if control.should_evaluate:\n",
    "            control_copy = deepcopy(control) ## If not deep copy control, the trainer would not evaluate the evaluation dataset\n",
    "            self._trainer.evaluate(eval_dataset=self._trainer.train_dataset, metric_key_prefix=\"train\")\n",
    "            return control_copy\n",
    "\n",
    "## Combination of multiple evaluation metrics\n",
    "def combination_compute_metrics2(eval_pred: EvalPrediction):\n",
    "    metrics = ['accuracy', 'bleu']\n",
    "    metric={}\n",
    "    for i in metrics:\n",
    "       metric[i] = evaluate.load(i)\n",
    "    predictions, labels = eval_pred.predictions.argmax(axis=1), eval_pred.label_ids\n",
    "    #logits, labels = eval_pred\n",
    "    #predictions = np.argmax(logits, axis=1)\n",
    "    metric_results={} ## Create dictionary to store Accuracy and Bleu metrics\n",
    "    for i in metrics:\n",
    "       metric_results[i]=metric[i].compute(predictions=predictions, references=labels)[i]\n",
    "    return metric_results\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AmgDeUuuq4QH"
   },
   "source": [
    "Main program begins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-3rvI8bRrXJf"
   },
   "source": [
    "To check if there is a CUDA GPU available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P_U9tIGArb0G",
    "outputId": "30bede3b-dc9f-4749-cc06-4f8d0f3f5116"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These codes are running on the device CUDA\n",
      "\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "if device == 'cuda':\n",
    "  print('These codes are running on the device CUDA' )\n",
    "else:\n",
    "  print('These codes are running on the device CPU' )\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b9XPjKa1rfc5"
   },
   "source": [
    "To load the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "acibrT7ErjB9"
   },
   "outputs": [],
   "source": [
    "with open('train.json', 'r') as file:\n",
    "  training_data = json.load(file)\n",
    "training_src = []  ## list\n",
    "training_label = [] ## list\n",
    "for i in training_data:\n",
    "  training_src.append(training_data[i]['disfluent'])\n",
    "  training_label.append(training_data[i]['original'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PaWkMEvtrmCI"
   },
   "source": [
    "To load the validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bP-MGaLLrpg2"
   },
   "outputs": [],
   "source": [
    "with open('dev.json', 'r') as file:\n",
    "  validation_data = json.load(file)\n",
    "validation_src = [] ## list\n",
    "validation_label = [] ## list\n",
    "for i in validation_data:\n",
    "  validation_src.append(validation_data[i]['disfluent'])\n",
    "  validation_label.append(validation_data[i]['original'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sAUCge5orryf"
   },
   "source": [
    "To augment training/validation datasets.\n",
    "\n",
    "If the original disfluent questions without data augmentation are only used for training, then you may comment out the following two statements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7FOhpuc_rvao"
   },
   "outputs": [],
   "source": [
    "DataAugmentation(training_src, training_label)\n",
    "DataAugmentation(validation_src, validation_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R7q5GDMXrxiU"
   },
   "source": [
    "To tokenize datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281,
     "referenced_widgets": [
      "7e89c50bc0b546348dad67ae147ad206",
      "b22df27f41c14551bad34b74d6a93043",
      "f1c00c456e9d4061b80577a473d6c6cf",
      "a1d6adc5e84d44048835ef7216336516",
      "3b40cdb71d9a402787f0c33b247ea239",
      "a075fe669d8e4295a246a6d972ee09c2",
      "56aba0d640be409c9ae1bb648647fc37",
      "7f0b54da146b44f7bc8913a1f0f6d97a",
      "8f8a5130f5c64ae0817bc8e91405c4cd",
      "8e9eefa8cdf94c1d8cafe2a88607aff1",
      "a506e7515fd14e56bbd60ea8d9053a38",
      "c3aa26a964de4ebdb56f98a3a5c4ea93",
      "8877d551cf1840939e105f5edceb2a7c",
      "61aef0e87a64401bb50f9997ca57704c",
      "8b3175ab1ba14a9aa9a862d246223a0d",
      "b31216594170454fb974353d9104f259",
      "cb80a2851dc6482d98c1f49e64c5a2e3",
      "6a1505e695634b2284006184df7b0ab5",
      "2c036e924e3c42148b2579e9cf3bb3cf",
      "4d012936c89f462fb81e914bb3740461",
      "a592db5f8b804ef6b879723c80876edf",
      "ca5abc56d706408ab70da44b5f0c4257",
      "e4fda89b8efd4a78bf7a6d24d228c2c0",
      "905916eb013f4d58b433b7285de6a5f8",
      "4337958e888847d89266d496f142a8c8",
      "697f16eae17f49cbb1808ad4791c86a4",
      "89a11819c34e4e2b937bdbed0dc261b8",
      "f62b78f124b94b7c9e04c16951a89fcb",
      "f9a50f491bda4c6eb33e1cf3ef209eea",
      "d887aa2afd7e49268da9f9538fa8082c",
      "d398738ea160453a9e1e343ba8c57372",
      "aaefcb34f85e4d90866bec44a3fe384a",
      "9fb5415b6d3e429291c4aa475d2214c8",
      "1e4596d9b39b45bdbd6dcbc0b41b26ea",
      "6a638a49723d44da9e43a63f4cc59590",
      "2f9c4f76f08341c9a160eb58ac37fe60",
      "71eb59ce04ec46388a3998852c8056bc",
      "e34de5042db74bc8b59ea571af39fc66",
      "7da2cb06c68d4ab997cd8a337024a523",
      "3fa096d2b40c44a5921723b260b6b41c",
      "18173a0811c64dd885442863f639ac0a",
      "e1aeb52619db424dbc678d2b13f2312b",
      "135d05777b3b4905be2bfa55592b6ed8",
      "3b6b3202efcb4bea92236511137ef104",
      "327eb42f94fb4f38aa086cbf5ff17ae1",
      "155f1437d7fb48a09297999c65f8dd72",
      "f8a77146414a4c35bcfbde7ddc476d46",
      "32eb2cb9b32549acab97da8da9318a68",
      "cac50f026c1d48bc9664b5b280b3e6b3",
      "4e4329ed3ca34fb7aff705f1ddefec9b",
      "ce854185fe8841ce8295307a3a05ff55",
      "e493a4c13477431bbd1d748c648f5d4a",
      "020bd3d84d0c4f81bb8d730a7744d80f",
      "083c66fec30549d980dcb4364e896988",
      "5fe55cf145bb44c2a8b190a70650b014"
     ]
    },
    "id": "_WWnQcf0r0PU",
    "outputId": "40671c80-4a74-4628-8241-5c7a2fd45595"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e89c50bc0b546348dad67ae147ad206",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3aa26a964de4ebdb56f98a3a5c4ea93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4fda89b8efd4a78bf7a6d24d228c2c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e4596d9b39b45bdbd6dcbc0b41b26ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "327eb42f94fb4f38aa086cbf5ff17ae1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "training_dataset = tokenize_dataset(training_src, training_label)\n",
    "validation_dataset = tokenize_dataset(validation_src, validation_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "trACfDb4r24T"
   },
   "source": [
    "To load a pre-trained model: BART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81,
     "referenced_widgets": [
      "5c27154964744c788568506cccf9d137",
      "26c4cda52f3b4b9f9e2e22afec036901",
      "9460fea1558a4ceb8f80806f1e5810bc",
      "6bcf2ce5b3ed4a3890bd65268d51c609",
      "dc9b92a25ba34d7d9a93df25f3ddaf1b",
      "87d19e64d05c47848c63d6d1272bef68",
      "bd500b2461c949c9b6f88839900d24e0",
      "382b9f502cd44010a57f918b13c20fb0",
      "f106bbc433df4824b68febed32fc5359",
      "aa1774c606e24d18a168fe7cd0869fe2",
      "3730e5b7147240249b21224c890672ea",
      "e19bc18c44994df38715dcc8503cb7f4",
      "26757d2e226044fbbc2fc2c41e1bab0f",
      "0304a05cf77c4430beaeb8ce59191bbe",
      "e23eabf0295b41ee9614b48db5b1af71",
      "66dc65be97ee483b87beae9a1dfb7118",
      "069bdb2aac22440a90e1192a078d8b0e",
      "2ad9af0652f9473089e251f0fd175f9b",
      "0ca982ebc469465ea3113e3993419eda",
      "e1258746d0a54a22802f05085a232b29",
      "47f9dc5a9e6449b8ad159aaad9e7e3de",
      "5407f4756f1e4643ad62ef716680525a"
     ]
    },
    "id": "oaEubeDXr6eM",
    "outputId": "0b39cb1f-aba1-47c0-b693-a56c69930b27"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c27154964744c788568506cccf9d137",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/1.02G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e19bc18c44994df38715dcc8503cb7f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.02G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = 'facebook/bart-large'\n",
    "model = BartForConditionalGeneration.from_pretrained(model_name).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VfLmUmbjr853"
   },
   "source": [
    "To define training argumentsr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qPulWERpr_xE"
   },
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "output_dir='./results',\n",
    "num_train_epochs=5,\n",
    "overwrite_output_dir=True,\n",
    "#do_train=True,\n",
    "#do_eval=True,\n",
    "per_device_train_batch_size=16,\n",
    "per_device_eval_batch_size=16,\n",
    "learning_rate=5e-5,\n",
    "#weight_decay=1e-2,\n",
    "#lr_scheduler_type='cosine',\n",
    "eval_strategy='epoch',\n",
    "save_strategy='epoch',\n",
    "#logging_strategy='epoch',\n",
    "logging_dir='./logs',\n",
    "logging_steps=20,\n",
    "fp16=True,\n",
    "load_best_model_at_end=True,\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "16JvGEX0sC0v"
   },
   "source": [
    "To create a Trainer instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Div7lzArsGFq",
    "outputId": "4a9020af-496b-4b2e-e513-1d9788ea7261"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipython-input-15-1986452107.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "trainer = Trainer(\n",
    "  train_dataset=training_dataset,\n",
    "  eval_dataset=validation_dataset,\n",
    "  model=model,\n",
    "  args=training_args,\n",
    "  tokenizer=BartTokenizer.from_pretrained('facebook/bart-large'),\n",
    "\n",
    "  ## To try different custom evaluaiton metrics\n",
    "  ## otherwise using the default evaluation metric\n",
    "  ## the default matric is 'loss'\n",
    "\n",
    "  #compute_metrics=accuracy_score,\n",
    "  #compute_metrics=bleu_score,\n",
    "  #compute_metrics=rouge_score,\n",
    "  #compute_metrics=combination_compute_metrics1,\n",
    "  #compute_metrics=combination_compute_metrics2,\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eGm2uoBXsLll"
   },
   "source": [
    "To fine-tune the BART model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 565
    },
    "id": "_JoluP3ZsVh_",
    "outputId": "db59aa2f-0369-4bd5-88cc-8c811044ad1f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
       "            function loadScript(url) {\n",
       "            return new Promise(function(resolve, reject) {\n",
       "                let newScript = document.createElement(\"script\");\n",
       "                newScript.onerror = reject;\n",
       "                newScript.onload = resolve;\n",
       "                document.body.appendChild(newScript);\n",
       "                newScript.src = url;\n",
       "            });\n",
       "            }\n",
       "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
       "            const iframe = document.createElement('iframe')\n",
       "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
       "            document.body.appendChild(iframe)\n",
       "            const handshake = new Postmate({\n",
       "                container: iframe,\n",
       "                url: 'https://wandb.ai/authorize'\n",
       "            });\n",
       "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
       "            handshake.then(function(child) {\n",
       "                child.on('authorize', data => {\n",
       "                    clearTimeout(timeout)\n",
       "                    resolve(data)\n",
       "                });\n",
       "            });\n",
       "            })\n",
       "        });\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize?ref=models\n",
      "wandb: Paste an API key from your profile and hit enter:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ··········\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mchendingjun68\u001b[0m (\u001b[33mchendingjun68-self-employed\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20250730_094321-3ys3sgxq</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/chendingjun68-self-employed/huggingface/runs/3ys3sgxq' target=\"_blank\">./results</a></strong> to <a href='https://wandb.ai/chendingjun68-self-employed/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/chendingjun68-self-employed/huggingface' target=\"_blank\">https://wandb.ai/chendingjun68-self-employed/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/chendingjun68-self-employed/huggingface/runs/3ys3sgxq' target=\"_blank\">https://wandb.ai/chendingjun68-self-employed/huggingface/runs/3ys3sgxq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4490' max='4490' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4490/4490 39:37, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.271500</td>\n",
       "      <td>0.248141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.124700</td>\n",
       "      <td>0.226405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.080500</td>\n",
       "      <td>0.217437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.045000</td>\n",
       "      <td>0.226649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.034300</td>\n",
       "      <td>0.245225</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py:3854: UserWarning: Moving the following attributes in the config to the generation config: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0}. You are seeing this warning because you've set generation parameters in the model config, as opposed to in the generation config.\n",
      "  warnings.warn(\n",
      "There were missing keys in the checkpoint model loaded: ['model.encoder.embed_tokens.weight', 'model.decoder.embed_tokens.weight', 'lm_head.weight'].\n"
     ]
    }
   ],
   "source": [
    "#trainer.add_callback(CustomCallback(trainer))\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2ZtFzBIqsZFC"
   },
   "source": [
    "To delete non-empty direcotry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OolY2S1QsdL6"
   },
   "outputs": [],
   "source": [
    "directory = './model'\n",
    "if os.path.isdir(directory):\n",
    "  shutil.rmtree(directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "edVbytiBsfuf"
   },
   "source": [
    "To save the well-trained model into the specified directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jc0n_co5sSOs",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "model.save_pretrained(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eOsaxY3_u-aK"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
